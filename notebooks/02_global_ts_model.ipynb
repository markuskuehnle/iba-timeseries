{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pipeline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "import optuna\n",
    "\n",
    "# -----------------------------------\n",
    "# Helpers\n",
    "# -----------------------------------\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def time_series_splits(df, n_folds=3, val_size=6):\n",
    "    \"\"\"Yield (train_df, val_df) forward‐chaining splits.\"\"\"\n",
    "    n = len(df)\n",
    "    for i in range(n_folds):\n",
    "        train_end = n - (n_folds - i) * val_size\n",
    "        val_start = train_end\n",
    "        val_end   = val_start + val_size\n",
    "        if val_end > n:\n",
    "            break\n",
    "        yield df.iloc[:train_end], df.iloc[val_start:val_end]\n",
    "\n",
    "def load_and_preprocess(data_path):\n",
    "    \"\"\"\n",
    "    Load CSV, filter dates, aggregate to monthly, create\n",
    "    the same features & dropped columns as in training.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_path, low_memory=False)\n",
    "    df[\"Kalendertag\"]    = pd.to_datetime(df[\"Kalendertag\"], errors=\"coerce\")\n",
    "    df[\"Eintrittsdatum\"] = pd.to_datetime(df[\"Eintrittsdatum\"], errors=\"coerce\")\n",
    "    df = df[df[\"Kalendertag\"] >= df[\"Eintrittsdatum\"]]\n",
    "    df[\"JahrMonat\"]      = pd.to_datetime(df[\"Kalendertag\"].dt.to_period(\"M\").astype(str))\n",
    "\n",
    "    monthly = (\n",
    "        df.groupby(\"JahrMonat\")\n",
    "          .agg({\n",
    "            \"BIWNAV AV Neug Wesu\":\"sum\",\n",
    "            \"Anz. NeuFamilien\":    \"sum\",\n",
    "            \"Anz. Neukunden\":      \"sum\",\n",
    "            \"P AV neu\":            \"sum\",\n",
    "            \"SpB AV\":              \"sum\",\n",
    "          })\n",
    "          .reset_index()\n",
    "          .rename(columns={\"BIWNAV AV Neug Wesu\":\"target\"})\n",
    "          .sort_values(\"JahrMonat\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Feature engineering\n",
    "    monthly[\"month\"]     = monthly[\"JahrMonat\"].dt.month\n",
    "    monthly[\"month_sin\"] = np.sin(2 * np.pi * monthly[\"month\"] / 12)\n",
    "    monthly[\"month_cos\"] = np.cos(2 * np.pi * monthly[\"month\"] / 12)\n",
    "    for col in [\"Anz. NeuFamilien\",\"Anz. Neukunden\",\"P AV neu\",\"SpB AV\"]:\n",
    "        monthly[f\"{col}_lag1\"] = monthly[col].shift(1)\n",
    "        monthly[f\"{col}_lag2\"] = monthly[col].shift(2)\n",
    "    monthly[\"target_t_plus_1\"] = monthly[\"target\"].shift(-1)\n",
    "\n",
    "    monthly = (\n",
    "        monthly\n",
    "        .drop(columns=[\n",
    "            \"month\",\n",
    "            \"Anz. NeuFamilien\",\"Anz. Neukunden\",\"P AV neu\",\"SpB AV\",\n",
    "            \"target\"\n",
    "        ])\n",
    "        .dropna(subset=[\"target_t_plus_1\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return monthly\n",
    "\n",
    "# -----------------------------------\n",
    "# Main orchestration\n",
    "# -----------------------------------\n",
    "def main(TEST_SIZE=6, N_TRIALS=30):\n",
    "    DATA_PATH  = \"../data/4_PrognoseCase_AV_NG_-_Daten.csv\"\n",
    "    MODEL_PATH = \"../models/global_xgb_model.pkl\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "    monthly       = load_and_preprocess(DATA_PATH)\n",
    "    train_val_df  = monthly.iloc[:-TEST_SIZE]\n",
    "    test_df       = monthly.iloc[-TEST_SIZE:]\n",
    "    feature_cols  = [c for c in monthly.columns if c not in [\"JahrMonat\",\"target_t_plus_1\"]]\n",
    "\n",
    "    # 1) Optuna hyperparameter tuning\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"objective\":        \"reg:squarederror\",\n",
    "            \"tree_method\":      \"hist\",\n",
    "            \"random_state\":     42,\n",
    "            \"verbosity\":        0,\n",
    "            \"max_depth\":        trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"learning_rate\":    trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\":        trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"n_estimators\":     trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        }\n",
    "        mape_scores = []\n",
    "        for tr_df, val_df in time_series_splits(train_val_df, n_folds=3, val_size=TEST_SIZE):\n",
    "            X_tr, y_tr   = tr_df[feature_cols], tr_df[\"target_t_plus_1\"]\n",
    "            X_val, y_val = val_df[feature_cols], val_df[\"target_t_plus_1\"]\n",
    "            model = XGBRegressor(**params)\n",
    "            model.fit(X_tr, y_tr)\n",
    "            preds = model.predict(X_val)\n",
    "            mape_scores.append(mean_absolute_percentage_error(y_val, preds))\n",
    "        return float(np.mean(mape_scores))\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "    best_params = study.best_trial.params\n",
    "    print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "    tuned = {\n",
    "        **best_params,\n",
    "        \"objective\":    \"reg:squarederror\",\n",
    "        \"random_state\": 42,\n",
    "        \"verbosity\":    0,\n",
    "    }\n",
    "\n",
    "    # 2) Train on train_val and evaluate on hold-out\n",
    "    prod_model = XGBRegressor(**tuned)\n",
    "    prod_model.fit(train_val_df[feature_cols], train_val_df[\"target_t_plus_1\"])\n",
    "    test_preds = prod_model.predict(test_df[feature_cols])\n",
    "    test_mae   = mean_absolute_error(test_df[\"target_t_plus_1\"], test_preds)\n",
    "    test_mape  = mean_absolute_percentage_error(test_df[\"target_t_plus_1\"], test_preds)\n",
    "    print(f\"Hold‐out Test ({TEST_SIZE} mo): MAE={test_mae:.0f}, MAPE={test_mape:.2f}%\")\n",
    "\n",
    "    # 3) Retrain on full data and save\n",
    "    final_model = XGBRegressor(**tuned)\n",
    "    final_model.fit(monthly[feature_cols], monthly[\"target_t_plus_1\"])\n",
    "    joblib.dump(final_model, MODEL_PATH)\n",
    "    print(f\"Saved tuned model to {MODEL_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_pipeline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def load_and_preprocess(data_path):\n",
    "    \"\"\"\n",
    "    Load the CSV, filter dates, aggregate to monthly and\n",
    "    apply the same feature‐engineering/dropping as in training.\n",
    "    Returns the prepared `monthly` DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_path, low_memory=False)\n",
    "    df[\"Kalendertag\"]    = pd.to_datetime(df[\"Kalendertag\"], errors=\"coerce\")\n",
    "    df[\"Eintrittsdatum\"] = pd.to_datetime(df[\"Eintrittsdatum\"], errors=\"coerce\")\n",
    "    df = df[df[\"Kalendertag\"] >= df[\"Eintrittsdatum\"]]\n",
    "    df[\"JahrMonat\"] = pd.to_datetime(df[\"Kalendertag\"].dt.to_period(\"M\").astype(str))\n",
    "\n",
    "    monthly = df.groupby(\"JahrMonat\").agg({\n",
    "        \"BIWNAV AV Neug Wesu\": \"sum\",\n",
    "        \"Anz. NeuFamilien\":     \"sum\",\n",
    "        \"Anz. Neukunden\":       \"sum\",\n",
    "        \"P AV neu\":             \"sum\",\n",
    "        \"SpB AV\":               \"sum\",\n",
    "    }).reset_index().rename(columns={\"BIWNAV AV Neug Wesu\": \"target\"})\n",
    "\n",
    "    monthly = monthly.sort_values(\"JahrMonat\").copy()\n",
    "    monthly[\"target_t\"]      = monthly[\"target\"]\n",
    "    monthly[\"month\"]         = monthly[\"JahrMonat\"].dt.month\n",
    "    monthly[\"month_sin\"]     = np.sin(2 * np.pi * monthly[\"month\"] / 12)\n",
    "    monthly[\"month_cos\"]     = np.cos(2 * np.pi * monthly[\"month\"] / 12)\n",
    "\n",
    "    for col in [\"Anz. NeuFamilien\",\"Anz. Neukunden\",\"P AV neu\",\"SpB AV\"]:\n",
    "        monthly[f\"{col}_lag1\"] = monthly[col].shift(1)\n",
    "        monthly[f\"{col}_lag2\"] = monthly[col].shift(2)\n",
    "\n",
    "    monthly[\"target_t_plus_1\"] = monthly[\"target\"].shift(-1)\n",
    "\n",
    "    # drop exactly the same columns as in training\n",
    "    monthly = monthly.drop(columns=[\n",
    "        \"month\",\n",
    "        \"Anz. NeuFamilien\",\"Anz. Neukunden\",\"P AV neu\",\"SpB AV\",\n",
    "        \"target\"\n",
    "    ])\n",
    "    return monthly.reset_index(drop=True)\n",
    "\n",
    "def forecast_periods(model_path, data_path, n_periods=7):\n",
    "    \"\"\"\n",
    "    Load the XGBoost model & data, then iteratively forecast `n_periods` ahead.\n",
    "    Returns a list of (JahrMonat (Timestamp), forecast_value).\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(model_path):\n",
    "        raise FileNotFoundError(f\"Model not found at {model_path}. Please run training first.\")\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    monthly = load_and_preprocess(data_path)\n",
    "    feature_cols = [c for c in monthly.columns if c not in [\"JahrMonat\",\"target_t\",\"target_t_plus_1\"]]\n",
    "\n",
    "    # seed with last known features\n",
    "    last_feats = monthly.iloc[-1][feature_cols].copy()\n",
    "    last_date  = monthly.iloc[-1][\"JahrMonat\"]\n",
    "\n",
    "    forecasts = []\n",
    "    for _ in range(n_periods):\n",
    "        next_date = last_date + pd.DateOffset(months=1)\n",
    "\n",
    "        # update cycle\n",
    "        sin = np.sin(2 * np.pi * next_date.month / 12)\n",
    "        cos = np.cos(2 * np.pi * next_date.month / 12)\n",
    "        feats = last_feats.copy()\n",
    "        feats[\"month_sin\"], feats[\"month_cos\"] = sin, cos\n",
    "\n",
    "        # build 1×n DataFrame so sklearn sees names\n",
    "        X_pred_df = pd.DataFrame([feats], columns=feature_cols)\n",
    "        y_pred    = model.predict(X_pred_df)[0]\n",
    "\n",
    "        forecasts.append((next_date, y_pred))\n",
    "\n",
    "        # advance\n",
    "        last_date  = next_date\n",
    "        # if you need to feed predictions back into lags/target, do it here:\n",
    "        # e.g. last_feats[\"target_lag1\"] = last_feats[\"target_lag2\"]\n",
    "        #       last_feats[\"target_lag2\"] = y_pred\n",
    "\n",
    "    return forecasts\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # point to your tuned XGBoost artifact\n",
    "    MODEL_PATH = \"../models/global_xgb_model.pkl\"\n",
    "    DATA_PATH  = \"../data/4_PrognoseCase_AV_NG_-_Daten.csv\"\n",
    "    results    = forecast_periods(MODEL_PATH, DATA_PATH, n_periods=7)\n",
    "\n",
    "    for period, value in results:\n",
    "        print(f\"{period.strftime('%Y-%m')}: {value:,.0f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
